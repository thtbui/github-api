{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1007faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [C:\\Users\\Vasilis\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Make selenium and chromedriver work for github.com\n",
    "# install also - pip install selenium , pip install webdriver_manager\n",
    "\n",
    "import selenium.webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "#driver = webdriver.Chrome()\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "base_url = \"https://github.com/search?\"\n",
    "driver.get(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adf5ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_page_urls(base_url, num_pages):\n",
    "    page_urls = []\n",
    "    \n",
    "    for counter in range(1, num_pages + 1):\n",
    "        full_url = base_url + \"p=\" + str(counter) + \"&q=open+education&type=Repositories\"\n",
    "        page_urls.append(full_url)\n",
    "        \n",
    "    return page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a33fc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/search?p=1&q=open+education&type=Repositories']\n"
     ]
    }
   ],
   "source": [
    "page_urls=generate_page_urls(base_url,1)\n",
    "print(page_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbad47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/PetoiCamp/OpenCat-Old\n",
      "1.3k\n",
      "/bugcrowd/bugcrowd_university\n",
      "2k\n",
      "/openeducat/openeducat_erp\n",
      "376\n",
      "/marwahmanbir/OpenEDU\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f1c47dad69ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgithub_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mgithub_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_github_urls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-f1c47dad69ab>\u001b[0m in \u001b[0;36mextract_github_urls\u001b[1;34m(page_urls)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[0mstars\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menter_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mstars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Link--secondary no-underline mr-3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"text-bold\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "#still doesn't work properly with selenium\n",
    "def extract_github_urls (page_urls):\n",
    "    github_list=[]\n",
    "    from time import sleep\n",
    " #first loop with page url(1 to 100)    \n",
    "    for loop_pages in page_urls:\n",
    "\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "        name_rep = requests.get(loop_pages)\n",
    "        soup = BeautifulSoup(name_rep.text, \"html.parser\")\n",
    "        name_rep=soup.find_all(class_=\"repo-list-item hx_hit-repo d-flex flex-justify-start py-4 public source\")\n",
    "      \n",
    " # We select the name of repos \n",
    " #second loop for the repositories(1-10)\n",
    "        for loop_repos in name_rep:\n",
    "            name_rep=loop_repos.find(\"a\").attrs[\"href\"]\n",
    "            print(name_rep)\n",
    "            github_list.append({\"Name Repository\": name_rep })\n",
    "    \n",
    "            # Command to enter inside of the Repository\n",
    "            enter_url=\"https://github.com/\"+name_rep\n",
    "            from time import sleep\n",
    "            for enter_repos in enter_url:\n",
    "                import requests\n",
    "                from bs4 import BeautifulSoup\n",
    "                stars= requests.get(enter_url)\n",
    "                soup = BeautifulSoup(stars.text, \"html.parser\")\n",
    "                stars=soup.find(class_=\"Link--secondary no-underline mr-3\").find(class_=\"text-bold\").get_text()\n",
    "            print(stars)\n",
    "            sleep(1)\n",
    "        github_list.append({\"Name Repository\": name_rep,\"Stars\":stars})          \n",
    "    sleep(1)   \n",
    "    return github_list\n",
    "github_list = extract_github_urls(page_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f934fe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(github_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap about but inside of a page because it takes more text \n",
    "\n",
    "url= 'https://github.com/traprajith/open-school-CE'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "about= requests.get(url)\n",
    "soup = BeautifulSoup(about.text, \"html.parser\")\n",
    "about=soup.find(\"p\",class_=\"f4 mb-3\").get_text()\n",
    "\n",
    "print(about)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41db1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scap Stars\n",
    "name_rep=(\"/PetoiCamp/OpenCat-Old\")\n",
    "enter_url=\"https://github.com/\"+name_rep\n",
    "for enter_repos in enter_url:\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    stars= requests.get(enter_url)\n",
    "    soup = BeautifulSoup(stars.text, \"html.parser\")\n",
    "    stars=soup.find(class_=\"Link--secondary no-underline mr-3\").find(class_=\"text-bold\").get_text()\n",
    "print(stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scap forks\n",
    "url= 'https://github.com/PetoiCamp/OpenCat-Old'\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "forks= requests.get(url)\n",
    "soup = BeautifulSoup(forks.text, \"html.parser\")\n",
    "\n",
    "forks=soup.find(class_=\"Link--secondary no-underline\").find(class_=\"text-bold\").get_text()\n",
    "\n",
    "print(forks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9953ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scap Language only the most used\n",
    "url= \"https://github.com/mahmoud/awesome-python-applications\"\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "lang= requests.get(url)\n",
    "soup = BeautifulSoup(lang.text,\"html.parser\")\n",
    "lang=soup.find(class_=\"color-text-primary text-bold mr-1\").get_text()\n",
    "        \n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef51ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
